import { useState, useRef, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Camera, X, Loader2 } from 'lucide-react';
import { useFaceLogin } from '@/hooks/useFaceLogin';
import { toast } from 'sonner';
import * as faceapi from 'face-api.js';

interface AdvancedFaceLoginVerifyProps {
  onSuccess?: () => void;
  onCancel?: () => void;
}

export const AdvancedFaceLoginVerify = ({ onSuccess, onCancel }: AdvancedFaceLoginVerifyProps) => {
  const [isCapturing, setIsCapturing] = useState(false);
  const [faceDetected, setFaceDetected] = useState(false);
  const [countdown, setCountdown] = useState(0);
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const { verifyFaceAndLogin, isVerifying } = useFaceLogin();

  useEffect(() => {
    loadModels();
    return () => {
      stopCamera();
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
      }
    };
  }, []);

  const loadModels = async () => {
    try {
      console.log('â³ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬Ù‡...');
      const MODEL_URL = '/models';
      
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
      ]);
      
      console.log('âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­');
      setModelsLoaded(true);
    } catch (error) {
      console.error('âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:', error);
      toast.error('ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬Ù‡');
    }
  };

  const startCamera = async () => {
    if (!modelsLoaded) {
      toast.error('ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬');
      return;
    }

    try {
      console.log('ğŸ¥ ÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          facingMode: 'user',
          width: { ideal: 640 },
          height: { ideal: 480 }
        } 
      });
      
      streamRef.current = stream;
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        
        videoRef.current.onloadedmetadata = () => {
          if (videoRef.current) {
            videoRef.current.play()
              .then(() => {
                console.log('âœ… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØªØ¹Ù…Ù„');
                setIsCapturing(true);
                startFaceDetection();
              })
              .catch((err) => {
                console.error('âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:', err);
                toast.error('ÙØ´Ù„ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§');
              });
          }
        };
      }
    } catch (error) {
      console.error('âŒ Ø®Ø·Ø£ ÙÙŠ ÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§:', error);
      toast.error('ÙØ´Ù„ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§');
    }
  };

  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
    }
    setIsCapturing(false);
    setFaceDetected(false);
  };

  const startFaceDetection = () => {
    if (!videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;

    // ØªØ¹ÙŠÙŠÙ† Ø­Ø¬Ù… Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    detectionIntervalRef.current = setInterval(async () => {
      if (!video || !canvas) return;

      const ctx = canvas.getContext('2d');
      if (!ctx) return;

      // Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      try {
        const detection = await faceapi.detectSingleFace(
          video, 
          new faceapi.TinyFaceDetectorOptions()
        ).withFaceLandmarks();

        if (detection) {
          setFaceDetected(true);
          
          // Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„ÙˆØ¬Ù‡
          const box = detection.detection.box;
          const centerX = box.x + box.width / 2;
          const centerY = box.y + box.height / 2;
          const radius = Math.max(box.width, box.height) * 0.6;

          // Ø¯Ø§Ø¦Ø±Ø© Ø®Ø¶Ø±Ø§Ø¡ Ø¹Ù†Ø¯ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡
          ctx.beginPath();
          ctx.arc(centerX, centerY, radius, 0, 2 * Math.PI);
          ctx.strokeStyle = '#22c55e';
          ctx.lineWidth = 4;
          ctx.stroke();

          // Ø±Ø³Ù… Ù…Ø¹Ø§Ù„Ù… Ø§Ù„ÙˆØ¬Ù‡
          const landmarks = detection.landmarks;
          ctx.fillStyle = '#22c55e';
          landmarks.positions.forEach((point: any) => {
            ctx.beginPath();
            ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
            ctx.fill();
          });

        } else {
          setFaceDetected(false);
          
          // Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø²Ø±Ù‚Ø§Ø¡ Ø¹Ù†Ø¯ Ø¹Ø¯Ù… Ø§ÙƒØªØ´Ø§Ù ÙˆØ¬Ù‡
          ctx.beginPath();
          ctx.arc(canvas.width / 2, canvas.height / 2, 150, 0, 2 * Math.PI);
          ctx.strokeStyle = '#3b82f6';
          ctx.lineWidth = 4;
          ctx.stroke();
        }
      } catch (error) {
        console.error('Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡:', error);
      }
    }, 100);
  };

  const captureAndVerify = async () => {
    if (!faceDetected) {
      toast.error('Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙˆØ¬Ù‡ ÙˆØ§Ø¶Ø­');
      return;
    }

    // Ø¹Ø¯Ø§Ø¯ ØªÙ†Ø§Ø²Ù„ÙŠ
    setCountdown(3);
    const countdownInterval = setInterval(() => {
      setCountdown(prev => {
        if (prev <= 1) {
          clearInterval(countdownInterval);
          return 0;
        }
        return prev - 1;
      });
    }, 1000);

    // Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¹Ø¯
    await new Promise(resolve => setTimeout(resolve, 3000));

    // Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØµÙˆØ±Ø©
    if (!videoRef.current || !canvasRef.current) return;

    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = 800;
    tempCanvas.height = 600;
    const ctx = tempCanvas.getContext('2d');
    
    if (ctx) {
      ctx.drawImage(videoRef.current, 0, 0, 800, 600);
      const imageBase64 = tempCanvas.toDataURL('image/jpeg', 0.7);
      
      stopCamera();
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆØ¬Ù‡
      const result = await verifyFaceAndLogin(imageBase64);
      if (result.success) {
        onSuccess?.();
      }
    }
  };

  return (
    <div className="space-y-4">
      <div className="text-center space-y-2">
        <h3 className="text-lg font-semibold">Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆØ¬Ù‡</h3>
        <p className="text-sm text-muted-foreground">
          Ø¶Ø¹ ÙˆØ¬Ù‡Ùƒ ÙÙŠ Ø§Ù„Ø¥Ø·Ø§Ø±
        </p>
      </div>

      <div className="relative bg-black rounded-lg overflow-hidden" style={{ aspectRatio: '4/3' }}>
        {!isCapturing && !isVerifying && (
          <div className="absolute inset-0 flex items-center justify-center">
            {!modelsLoaded ? (
              <div className="text-center text-white space-y-2">
                <Loader2 className="w-12 h-12 animate-spin mx-auto" />
                <p>ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¬Ù‡...</p>
              </div>
            ) : (
              <Button onClick={startCamera} size="lg" className="gap-2">
                <Camera className="w-5 h-5" />
                ÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
              </Button>
            )}
          </div>
        )}

        {isCapturing && (
          <>
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
              className="w-full h-full object-cover"
            />
            <canvas
              ref={canvasRef}
              className="absolute inset-0 w-full h-full"
            />
            
            {countdown > 0 && (
              <div className="absolute inset-0 flex items-center justify-center">
                <div className="bg-black/70 rounded-full w-32 h-32 flex items-center justify-center">
                  <span className="text-white text-6xl font-bold">{countdown}</span>
                </div>
              </div>
            )}

            <div className="absolute bottom-4 left-0 right-0 flex justify-center">
              <div className={`px-4 py-2 rounded-full flex items-center gap-2 ${
                faceDetected ? 'bg-green-500' : 'bg-blue-500'
              }`}>
                <div className="w-3 h-3 rounded-full bg-white animate-pulse" />
                <span className="text-white text-sm font-medium">
                  {faceDetected ? 'âœ“ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡' : 'Ø¶Ø¹ ÙˆØ¬Ù‡Ùƒ ÙÙŠ Ø§Ù„Ø¥Ø·Ø§Ø±...'}
                </span>
              </div>
            </div>
          </>
        )}

        {isVerifying && (
          <div className="absolute inset-0 bg-black/70 flex items-center justify-center">
            <div className="text-center text-white space-y-2">
              <Loader2 className="w-12 h-12 animate-spin mx-auto" />
              <p className="text-lg font-semibold">Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆØ¬Ù‡...</p>
            </div>
          </div>
        )}
      </div>

      <div className="flex gap-2 justify-center">
        {isCapturing && !isVerifying && countdown === 0 && (
          <>
            <Button 
              onClick={captureAndVerify} 
              size="lg" 
              className="gap-2"
              disabled={!faceDetected}
            >
              <Camera className="w-5 h-5" />
              Ø§Ù„ØªÙ‚Ø§Ø· ÙˆØ§Ù„ØªØ­Ù‚Ù‚
            </Button>
            <Button onClick={stopCamera} variant="outline" size="lg">
              <X className="w-5 h-5" />
              Ø¥Ù„ØºØ§Ø¡
            </Button>
          </>
        )}

        {!isCapturing && !isVerifying && onCancel && (
          <Button onClick={onCancel} variant="outline" size="lg">
            Ø¥Ù„ØºØ§Ø¡
          </Button>
        )}
      </div>
    </div>
  );
};